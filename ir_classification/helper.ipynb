{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_classification import datasets, models\n",
    "from ir_classification import vocab as ir_vocab\n",
    "from ir_classification import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ir_vocab.create_vocab_from_tsv(\"../datasets/systematic_review/phase1.train.shuf.tsv\", [2], ngrams=1)\n",
    "data_columns = [2]\n",
    "train_dataset = datasets.TSVRawTextMapDataset(\"../datasets/systematic_review/phase1.train.shuf.tsv\", data_columns)\n",
    "val_dataset = datasets.TSVRawTextMapDataset(\"../datasets/systematic_review/phase1.dev.shuf.tsv\", data_columns)\n",
    "label_transform = lambda x: x if x > 0 else 0\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "text_transform = lambda x: list(ngrams_iterator(tokenizer(x), 1))\n",
    "dataloader = datasets.create_torch_dataloader(train_dataset, vocab,  label_transform, text_transform, weighted=True, batch_size=8)\n",
    "val_dataloader = datasets.create_torch_dataloader(val_dataset, vocab,  label_transform, text_transform, weighted=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 64\n",
    "model = models.EmbeddingBagLinearModel(vocab_size, embedding_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2708/2708 [00:14<00:00, 191.55 batch/s, accurracy=1, loss=0.124]\n",
      "Validation: 0: 100%|██████████| 607/607 [00:02<00:00, 254.06 batch/s, accurracy=1, loss=0.0102]\n",
      "Epoch 1: 100%|██████████| 2708/2708 [00:13<00:00, 201.70 batch/s, accurracy=1, loss=0.0309]\n",
      "Validation: 1: 100%|██████████| 607/607 [00:02<00:00, 258.60 batch/s, accurracy=1, loss=0.0159]\n",
      "Epoch 2: 100%|██████████| 2708/2708 [00:13<00:00, 194.60 batch/s, accurracy=1, loss=0.118]\n",
      "Validation: 2: 100%|██████████| 607/607 [00:02<00:00, 274.62 batch/s, accurracy=1, loss=0.136]\n",
      "Epoch 3: 100%|██████████| 2708/2708 [00:14<00:00, 192.02 batch/s, accurracy=1, loss=0.0201]\n",
      "Validation: 3: 100%|██████████| 607/607 [00:02<00:00, 253.14 batch/s, accurracy=1, loss=0.00377]\n",
      "Epoch 4: 100%|██████████| 2708/2708 [00:13<00:00, 204.40 batch/s, accurracy=1, loss=0.000683]\n",
      "Validation: 4: 100%|██████████| 607/607 [00:02<00:00, 252.47 batch/s, accurracy=0.5, loss=2.86]\n",
      "Epoch 5: 100%|██████████| 2708/2708 [00:13<00:00, 196.45 batch/s, accurracy=1, loss=0.000797]\n",
      "Validation: 5: 100%|██████████| 607/607 [00:02<00:00, 257.24 batch/s, accurracy=1, loss=0.00625]\n",
      "Epoch 6: 100%|██████████| 2708/2708 [00:13<00:00, 200.64 batch/s, accurracy=1, loss=0.000572]\n",
      "Validation: 6: 100%|██████████| 607/607 [00:02<00:00, 264.93 batch/s, accurracy=0.5, loss=2.68]\n",
      "Epoch 7: 100%|██████████| 2708/2708 [00:12<00:00, 213.16 batch/s, accurracy=1, loss=0.00737]\n",
      "Validation: 7: 100%|██████████| 607/607 [00:02<00:00, 260.21 batch/s, accurracy=1, loss=0]\n",
      "Epoch 8: 100%|██████████| 2708/2708 [00:12<00:00, 209.22 batch/s, accurracy=1, loss=0.000208]\n",
      "Validation: 8: 100%|██████████| 607/607 [00:02<00:00, 285.87 batch/s, accurracy=1, loss=1.13e-6]\n",
      "Epoch 9: 100%|██████████| 2708/2708 [00:13<00:00, 201.34 batch/s, accurracy=1, loss=0.00107]\n",
      "Validation: 9: 100%|██████████| 607/607 [00:02<00:00, 243.55 batch/s, accurracy=1, loss=0.0276]\n",
      "Epoch 10: 100%|██████████| 2708/2708 [00:13<00:00, 198.43 batch/s, accurracy=1, loss=0.000711]\n",
      "Validation: 10: 100%|██████████| 607/607 [00:02<00:00, 250.80 batch/s, accurracy=1, loss=0.000209]\n",
      "Epoch 11: 100%|██████████| 2708/2708 [00:13<00:00, 202.11 batch/s, accurracy=1, loss=0.000888]\n",
      "Validation: 11: 100%|██████████| 607/607 [00:02<00:00, 297.47 batch/s, accurracy=1, loss=0]\n",
      "Epoch 12: 100%|██████████| 2708/2708 [00:12<00:00, 218.99 batch/s, accurracy=1, loss=0.00179]\n",
      "Validation: 12: 100%|██████████| 607/607 [00:02<00:00, 267.60 batch/s, accurracy=1, loss=4.11e-6]\n",
      "Epoch 13: 100%|██████████| 2708/2708 [00:13<00:00, 206.99 batch/s, accurracy=1, loss=0.000312]\n",
      "Validation: 13: 100%|██████████| 607/607 [00:02<00:00, 238.92 batch/s, accurracy=1, loss=4.17e-7]\n",
      "Epoch 14: 100%|██████████| 2708/2708 [00:14<00:00, 189.09 batch/s, accurracy=1, loss=0.0018]\n",
      "Validation: 14: 100%|██████████| 607/607 [00:02<00:00, 245.02 batch/s, accurracy=1, loss=0]\n",
      "Epoch 15: 100%|██████████| 2708/2708 [00:13<00:00, 202.97 batch/s, accurracy=1, loss=0.000389]\n",
      "Validation: 15: 100%|██████████| 607/607 [00:02<00:00, 264.57 batch/s, accurracy=1, loss=0.00121]\n",
      "Epoch 16: 100%|██████████| 2708/2708 [00:13<00:00, 197.17 batch/s, accurracy=1, loss=0.000894]\n",
      "Validation: 16: 100%|██████████| 607/607 [00:02<00:00, 293.87 batch/s, accurracy=1, loss=5.54e-6]\n",
      "Epoch 17: 100%|██████████| 2708/2708 [00:13<00:00, 201.37 batch/s, accurracy=1, loss=0.000376]\n",
      "Validation: 17: 100%|██████████| 607/607 [00:02<00:00, 284.73 batch/s, accurracy=0.5, loss=4.08]\n",
      "Epoch 18: 100%|██████████| 2708/2708 [00:13<00:00, 205.60 batch/s, accurracy=0.833, loss=0.245]\n",
      "Validation: 18: 100%|██████████| 607/607 [00:02<00:00, 256.51 batch/s, accurracy=1, loss=1.19e-7]\n",
      "Epoch 19: 100%|██████████| 2708/2708 [00:12<00:00, 210.91 batch/s, accurracy=1, loss=2.74e-5]\n",
      "Validation: 19: 100%|██████████| 607/607 [00:02<00:00, 286.54 batch/s, accurracy=1, loss=8.46e-6]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "EPOCHS = 20 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 8 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"max\", patience=2)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    start_iter = len(dataloader) * i\n",
    "    train.train_epoch(i, model, optimizer, criterion, dataloader, start_iter=start_iter, writer=writer)\n",
    "    validation_results = train.evaluate_epoch(i, model, criterion, val_dataloader, writer)\n",
    "    scheduler.step(validation_results[\"precision\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"state_dict.pth\", mode=\"wb\") as f:\n",
    "    torch.save(model.state_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "labels = []\n",
    "for batch in val_dataloader:\n",
    "    label, text, offset = batch\n",
    "    pred_label = train.predict(model, text)\n",
    "    preds.append(pred_label)\n",
    "    labels.append(label)\n",
    "\n",
    "average_results = {key: aggregate_results[key] / tepoch.total for key in aggregate_results}\n",
    "\n",
    "writer.add_scalars(\"validation\", average_results, epoch_num)\n",
    "return average_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2c370576f24a547f2bd7f1badbf1e39ac1d010b680ddb4523878c870f4696a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ir-classification-_Pgcz6ju-py3.9': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
